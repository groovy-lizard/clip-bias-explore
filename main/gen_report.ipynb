{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = \"/home/lazye/Documents/ufrgs/mcs/clip/clip-bias-explore/\\\n",
    "fair-face-classification\"\n",
    "RESULTS_PATH = ROOT + \"/data/results\"\n",
    "\n",
    "# original paper preds df with race_gender preds\n",
    "opd_df = pd.read_csv(RESULTS_PATH+\"/original_paper_preds.csv\")\n",
    "\n",
    "# top synm preds df\n",
    "topk_df = pd.read_csv(RESULTS_PATH+\"/top_k_synms.csv\")\n",
    "\n",
    "# avg sum synm preds df\n",
    "avg_df = pd.read_csv(RESULTS_PATH+\"/avg_sum_synms.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df, col, val):\n",
    "    return df[df[col] == val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original CLIP Paper Predictions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        file  age gender        race          gender_preds\n",
      "0  val/1.jpg  3-9   Male  East Asian  Southeast Asian_Male\n",
      "\n",
      "transforming gender_preds to binary classes...\n",
      "\n",
      "        file  age gender        race gender_preds\n",
      "0  val/1.jpg  3-9   Male  East Asian         Male\n"
     ]
    }
   ],
   "source": [
    "opd_df.drop(columns=['service_test'], inplace=True)\n",
    "print(opd_df.head(1))\n",
    "print('\\ntransforming gender_preds to binary classes...\\n')\n",
    "opd_df['gender_preds'] = opd_df['gender_preds'].map(lambda x: x.split('_')[-1])\n",
    "print(opd_df.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set info:\n",
      "\n",
      "---------------\n",
      "Race info:\n",
      "\n",
      "                 race_count race_percent\n",
      "race                                    \n",
      "White                  2085        19.0%\n",
      "Latino_Hispanic        1623        14.8%\n",
      "Black                  1556        14.2%\n",
      "East Asian             1550        14.2%\n",
      "Indian                 1516        13.8%\n",
      "\n",
      "Gender info:\n",
      "\n",
      "        gender_count gender_percent\n",
      "gender                             \n",
      "Male            5792          52.9%\n",
      "Female          5162          47.1%\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Validation set info:\\n\")\n",
    "print(\"-\"*15)\n",
    "race_count = opd_df.race.value_counts()\n",
    "race_percent = opd_df.race.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "gender_count = opd_df.gender.value_counts()\n",
    "gender_percent = opd_df.gender.value_counts(normalize=True).mul(100).round(1).astype(str) + '%'\n",
    "\n",
    "val_info_race = {\"race_count\": race_count,\n",
    "                 \"race_percent\": race_percent}\n",
    "\n",
    "val_info_race_df = pd.DataFrame(val_info_race)\n",
    "print(\"Race info:\\n\")\n",
    "print(val_info_race_df.head())\n",
    "\n",
    "val_info_gender = {\"gender_count\": gender_count,\n",
    "                   \"gender_percent\": gender_percent}\n",
    "\n",
    "val_info_gender_df = pd.DataFrame(val_info_gender)\n",
    "print(\"\\nGender info:\\n\")\n",
    "print(val_info_gender_df.head())\n",
    "print(\"-\"*15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Synonyms Prediction Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 1 Synms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_acc(df):\n",
    "    return accuracy_score(df['gender'], df['gender_preds'])\n",
    "\n",
    "def acc_by_col(df, col):\n",
    "    for unique in df[col].unique():\n",
    "        col_df = df[df[col] == unique]\n",
    "        col_acc = gender_acc(col_df)\n",
    "        print(f\"{unique} predictions accuracy: {round(col_acc, 2)}\")\n",
    "\n",
    "def gen_report(df, pred_name):\n",
    "    print(f\"# {pred_name} info:\\n\")\n",
    "    print(\"-\"*20)\n",
    "\n",
    "    print(\"\\n## General Accuracy\")\n",
    "    gen_acc = gender_acc(df)\n",
    "    gen_miss = df[df['gender'] != df['gender_preds']]\n",
    "    print(f\"Prediction error count: {len(gen_miss)}\")\n",
    "    print(f\"Prediction accuracy score: {round(gen_acc, 2)}\")\n",
    "\n",
    "    print(\"\\n## Accuracy by gender\")\n",
    "    male_df = filter_df(df, 'gender', 'Male')\n",
    "    male_acc = gender_acc(male_df)\n",
    "    female_df = filter_df(df, 'gender', 'Female')\n",
    "    female_acc = gender_acc(female_df)\n",
    "    print(f\"Male: {round(male_acc, 2)}\")\n",
    "    print(f\"Female: {round(female_acc, 2)}\")\n",
    "\n",
    "    print(\"\\n## Accuracy by race\")\n",
    "    acc_by_col(df, 'race')\n",
    "\n",
    "    print(\"\\n## Accuracy by age\")\n",
    "    acc_by_col(df, 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Top 1 Synonym Prediction info:\n",
      "\n",
      "--------------------\n",
      "\n",
      "## General Accuracy\n",
      "Prediction error count: 541\n",
      "Prediction accuracy score: 0.95\n",
      "\n",
      "## Accuracy by gender\n",
      "Male: 0.96\n",
      "Female: 0.93\n",
      "\n",
      "## Accuracy by race\n",
      "East Asian predictions accuracy: 0.95\n",
      "White predictions accuracy: 0.95\n",
      "Latino_Hispanic predictions accuracy: 0.96\n",
      "Southeast Asian predictions accuracy: 0.95\n",
      "Black predictions accuracy: 0.92\n",
      "Indian predictions accuracy: 0.96\n",
      "Middle Eastern predictions accuracy: 0.98\n",
      "\n",
      "## Accuracy by age\n",
      "3-9 predictions accuracy: 0.87\n",
      "50-59 predictions accuracy: 0.98\n",
      "30-39 predictions accuracy: 0.98\n",
      "20-29 predictions accuracy: 0.97\n",
      "more than 70 predictions accuracy: 0.97\n",
      "40-49 predictions accuracy: 0.98\n",
      "10-19 predictions accuracy: 0.91\n",
      "60-69 predictions accuracy: 0.96\n",
      "0-2 predictions accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "gen_report(topk_df, \"Top 1 Synonym Prediction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Original Paper Predictions info:\n",
      "\n",
      "--------------------\n",
      "\n",
      "## General Accuracy\n",
      "Prediction error count: 534\n",
      "Prediction accuracy score: 0.95\n",
      "\n",
      "## Accuracy by gender\n",
      "Male: 0.96\n",
      "Female: 0.94\n",
      "\n",
      "## Accuracy by race\n",
      "East Asian predictions accuracy: 0.95\n",
      "White predictions accuracy: 0.96\n",
      "Latino_Hispanic predictions accuracy: 0.96\n",
      "Southeast Asian predictions accuracy: 0.95\n",
      "Black predictions accuracy: 0.91\n",
      "Indian predictions accuracy: 0.95\n",
      "Middle Eastern predictions accuracy: 0.98\n",
      "\n",
      "## Accuracy by age\n",
      "3-9 predictions accuracy: 0.87\n",
      "50-59 predictions accuracy: 0.97\n",
      "30-39 predictions accuracy: 0.98\n",
      "20-29 predictions accuracy: 0.97\n",
      "more than 70 predictions accuracy: 0.95\n",
      "40-49 predictions accuracy: 0.98\n",
      "10-19 predictions accuracy: 0.91\n",
      "60-69 predictions accuracy: 0.96\n",
      "0-2 predictions accuracy: 0.83\n"
     ]
    }
   ],
   "source": [
    "gen_report(opd_df, \"Original Paper Predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
