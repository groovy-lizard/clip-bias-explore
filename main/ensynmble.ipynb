{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Caption Structure\n",
    "\n",
    "Each component should have a list of synonyms, a list of combinations should be generated.\n",
    "\n",
    "## Caption Structure:\n",
    "\n",
    "(age) (race) (gender)\n",
    "\n",
    "**Age**:\n",
    "\n",
    "- Old\n",
    "- Young\n",
    "- Middle-aged\n",
    "\n",
    "**Race**:\n",
    "\n",
    "- White\n",
    "- Black\n",
    "- Asian\n",
    "- Latino_Hispanic\n",
    "- Indian\n",
    "- East Asian\n",
    "- Southeast Asian\n",
    "- Middle Eastern\n",
    "\n",
    "**Gender**:\n",
    "\n",
    "- Man\n",
    "- Woman\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet as wn\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def a_or_an(word):\n",
    "    vowels = ['a', 'e', 'i', 'o', 'u']\n",
    "    if word[0] in vowels:\n",
    "        return \"an\"\n",
    "    else:\n",
    "        return \"a\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    synonyms = set()\n",
    "    for syn in wn.synsets(word):\n",
    "        for l in syn.lemmas():\n",
    "            synonyms.add(l.name())\n",
    "        for hyp in syn.hyponyms():\n",
    "            for l in hyp.lemmas():\n",
    "                synonyms.add(l.name())\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arg_combiner(a_list, r_list, g_list):\n",
    "    \"\"\"Combine the elements of a,r,g lists containing\n",
    "    ages, races and genders, respectively.\"\"\"\n",
    "    arg_d = {}\n",
    "\n",
    "    for gender in g_list:\n",
    "        arg_d[gender] = f\"a photo of a {gender}\"\n",
    "    for race in r_list:\n",
    "        arg_d[f\"{race}_{gender}\"] = \"a photo of \" + a_or_an(race) + f\" {race} {gender}\"\n",
    "        for age in a_list:\n",
    "            arg_d[f\"{age}_{race}_{gender}\"] = \"a photo of \" + a_or_an(age) + f\" {age} {race} {gender}\"\n",
    "    for age in a_list:\n",
    "        arg_d[f\"{age}_{gender}\"] = \"a photo of a \" + a_or_an(age) + f\" {age} {gender}\"\n",
    "\n",
    "    return arg_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_list = ['young', 'old', 'middle-aged']\n",
    "race_list = ['black', 'white', 'hispanic', 'latino', 'indian', 'asian', 'arabic']\n",
    "gender_list = ['man', 'woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_d = arg_combiner(a_list=age_list, r_list=race_list, g_list=gender_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('caption_rad.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(arg_d, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- botar soh os combo sem os sinonimos em um json e criar os embeddings (foi)\n",
    "- filtrar os sinonimos dos combos e achar como visualizar melhor eles pra decidir como filtrar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
