{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading model...\n",
      "Done! Model loaded to cuda device\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "print('\\nLoading model...')\n",
    "available_models = ['RN50', 'RN101', 'RN50x4', 'RN50x16']\n",
    "layers = ['layer4', 'layer3', 'layer2', 'layer1']\n",
    "\n",
    "clip_model = available_models[0]\n",
    "saliency_layer = layers[0]\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(clip_model, device=device, jit=False)\n",
    "print(f\"Done! Model loaded to {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/lazye/Documents/ufrgs/mcs/datasets/FairFace/\"\n",
    "fface_df = pd.read_csv(f\"{path}/train/fairface_label_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/1.jpg</td>\n",
       "      <td>50-59</td>\n",
       "      <td>Male</td>\n",
       "      <td>East Asian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/2.jpg</td>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/3.jpg</td>\n",
       "      <td>3-9</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/4.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/5.jpg</td>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          file    age  gender        race  service_test\n",
       "0  train/1.jpg  50-59    Male  East Asian          True\n",
       "1  train/2.jpg  30-39  Female      Indian         False\n",
       "2  train/3.jpg    3-9  Female       Black         False\n",
       "3  train/4.jpg  20-29  Female      Indian          True\n",
       "4  train/5.jpg  20-29  Female      Indian          True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fface_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_embds_df = pd.read_pickle('woman_embeddings.csv')\n",
    "man_embds_df = pd.read_pickle('man_embeddings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(img_embd, classes):\n",
    "    \"\"\"Softmax of pairs of 'img_embd' and each class of 'classes'\"\"\"\n",
    "    image_features = torch.from_numpy(img_embd).to(device)\n",
    "\n",
    "    text_inputs = torch.cat(\n",
    "        [clip.tokenize(f\"a photo of a {c}\") for c in classes]).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(text_inputs)\n",
    "    \n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "    similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "    values, indices = similarity[0].topk(len(similarity[0]))\n",
    "    scores = list()\n",
    "    for value, index in zip(values, indices):\n",
    "        scores.append((classes[index], round(100 * value.item(), 2)))\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('man', 82.23), ('woman', 17.79)]\n"
     ]
    }
   ],
   "source": [
    "labels = ['man', 'woman']\n",
    "print(get_scores(man_embds_df.iloc[0]['embeddings'], labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_embds(emb_df, classes):\n",
    "    results = dict()\n",
    "\n",
    "    text_inputs = torch.cat(\n",
    "        [clip.tokenize(f\"a photo of a {c}\") for c in classes]).to(device)\n",
    "    with torch.no_grad():\n",
    "        text_features = model.encode_text(text_inputs)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    for _, emb in emb_df.iterrows():\n",
    "        name = emb['file']\n",
    "        image_features = emb['embeddings']\n",
    "        image_features = torch.from_numpy(image_features).to(device)\n",
    "        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "        values, indices = similarity[0].topk(len(similarity[0]))\n",
    "        scores = list()\n",
    "        for value, index in zip(values, indices):\n",
    "            scores.append((classes[index], round(100 * value.item(), 2)))\n",
    "        results[name] = scores\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "man_results = eval_embds(man_embds_df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "woman_results = eval_embds(woman_embds_df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_scores = dict()\n",
    "files = list()\n",
    "predicts = list()\n",
    "\n",
    "for key, value in man_results.items():\n",
    "    files.append(key)\n",
    "    win_class = value[0][0]\n",
    "    if win_class == \"woman\":\n",
    "        predicts.append('Female')\n",
    "    else:\n",
    "        predicts.append('Male')\n",
    "\n",
    "for key, value in woman_results.items():\n",
    "    files.append(key)\n",
    "    win_class = value[0][0]\n",
    "    if win_class == \"woman\":\n",
    "        predicts.append('Female')\n",
    "    else:\n",
    "        predicts.append('Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_scores['file'] = files\n",
    "gender_scores['gender_preds'] = predicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_scores = pd.DataFrame(data=gender_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fface_df = fface_df.set_index('file').join(gender_scores.set_index('file'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>race</th>\n",
       "      <th>service_test</th>\n",
       "      <th>gender_preds</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train/6.jpg</th>\n",
       "      <td>20-29</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>True</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train/8.jpg</th>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train/16.jpg</th>\n",
       "      <td>30-39</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train/19.jpg</th>\n",
       "      <td>0-2</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train/30.jpg</th>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train/86711.jpg</th>\n",
       "      <td>3-9</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train/86722.jpg</th>\n",
       "      <td>0-2</td>\n",
       "      <td>Male</td>\n",
       "      <td>Black</td>\n",
       "      <td>False</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train/86723.jpg</th>\n",
       "      <td>20-29</td>\n",
       "      <td>Female</td>\n",
       "      <td>Middle Eastern</td>\n",
       "      <td>True</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train/86735.jpg</th>\n",
       "      <td>10-19</td>\n",
       "      <td>Female</td>\n",
       "      <td>Indian</td>\n",
       "      <td>True</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>train/86736.jpg</th>\n",
       "      <td>10-19</td>\n",
       "      <td>Male</td>\n",
       "      <td>Southeast Asian</td>\n",
       "      <td>True</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8469 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   age  gender             race  service_test gender_preds\n",
       "file                                                                      \n",
       "train/6.jpg      20-29    Male            White          True       Female\n",
       "train/8.jpg      30-39  Female           Indian          True         Male\n",
       "train/16.jpg     30-39  Female            White         False         Male\n",
       "train/19.jpg       0-2  Female            Black         False         Male\n",
       "train/30.jpg     20-29  Female            Black         False         Male\n",
       "...                ...     ...              ...           ...          ...\n",
       "train/86711.jpg    3-9    Male            Black         False       Female\n",
       "train/86722.jpg    0-2    Male            Black         False       Female\n",
       "train/86723.jpg  20-29  Female   Middle Eastern          True         Male\n",
       "train/86735.jpg  10-19  Female           Indian          True         Male\n",
       "train/86736.jpg  10-19    Male  Southeast Asian          True       Female\n",
       "\n",
       "[8469 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fface_df[fface_df['gender'] != fface_df['gender_preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "fface_df.to_csv('./fface_gender_preds.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clipenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
